{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/13 16:40:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - model_name: ann_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ann_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ann_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ann_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ann_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ann_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ann_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ann_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ann_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ann_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ann_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ann_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ann_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ann_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ann_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ann_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: apcnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: apcnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: apcnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: apcnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: apcnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: apcnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: apcnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: apcnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: apcnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: apcnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: apcnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: apcnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: beit-base_upernet_8xb2-160k_ade20k-640x640\n",
      "model_name: beit-large_upernet_8xb1-amp-160k_ade20k-640x640\n",
      "model_name: bisenetv1_r18-d32_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r18-d32-in1k-pre_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r18-d32-in1k-pre_4xb8-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r50-d32_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r50-d32-in1k-pre_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r18-d32_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r18-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r50-d32_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r50-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r50-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r101-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv2_fcn_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv2_fcn_4xb4-ohem-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv2_fcn_4xb8-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv2_fcn_4xb4-amp-160k_cityscapes-1024x1024\n",
      "model_name: ccnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ccnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ccnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ccnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ccnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ccnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ccnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ccnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ccnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ccnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ccnet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ccnet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: cgnet_fcn_4xb4-60k_cityscapes-680x680\n",
      "model_name: cgnet_fcn_4xb8-60k_cityscapes-512x1024\n",
      "model_name: convnext-tiny_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: convnext-small_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: convnext-base_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: convnext-base_upernet_8xb2-amp-160k_ade20k-640x640\n",
      "model_name: convnext-large_upernet_8xb2-amp-160k_ade20k-640x640\n",
      "model_name: convnext-xlarge_upernet_8xb2-amp-160k_ade20k-640x640\n",
      "model_name: danet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: danet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: danet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: danet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: danet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: danet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: danet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: danet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: danet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: danet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: danet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: danet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: danet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: danet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: danet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: danet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ddrnet_23-slim_in1k-pre_2xb6-120k_cityscapes-1024x1024\n",
      "model_name: ddrnet_23_in1k-pre_2xb6-120k_cityscapes-1024x1024\n",
      "model_name: deeplabv3_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101-d16-mg124_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d16-mg124_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: deeplabv3_r50-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ddeeplabv3plus_r101-d16-mg124_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d16-mg124_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_loveda-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_loveda-512x512\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_isaid-896x896\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_isaid-896x896\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-300k_mapillay_v1_65-1280x1280\n",
      "model_name: dmnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dmnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dmnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dmnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dmnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dmnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dmnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dmnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dmnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dmnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dmnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dmnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dnl_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dnl_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dnl_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dnl_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dnl_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dnl_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dnl_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dnl_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dnl_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dnl_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dnl_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dnl_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dpt_vit-b16_8xb2-160k_ade20k-512x512\n",
      "model_name: eemanet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: emanet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: emanet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: emanet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: encnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: encnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: encnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: encnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: encnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: encnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: encnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: encnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: encnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: encnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: encnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: encnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: erfnet_fcn_4xb4-160k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb4-80k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb4-160k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb4-80k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb4-160k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb4-80k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb4-160k_ade20k-512x512\n",
      "model_name: fast_scnn_8xb4-160k_cityscapes-512x1024\n",
      "model_name: fcn_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: fcn_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r50-d16_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r50-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r50-d16_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn-d6_r50-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r101-d16_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r101-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r101-d16_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn-d6_r101-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r50b-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r50b-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r101b-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r101b-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_r101-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: fcn_r101-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: fcn_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: fcn_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: gcnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: gcnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: gcnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: gcnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: gcnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: gcnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: gcnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: gcnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: gcnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: gcnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: gcnet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: gcnet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr18s_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_hr18_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_hr48_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_hr18s_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_hr18_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_hr48_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_hr18s_4xb2-160k_cityscapes-512x1024\n",
      "model_name: fcn_hr18_4xb2-160k_cityscapes-512x1024\n",
      "model_name: fcn_hr48_4xb2-160k_cityscapes-512x1024\n",
      "model_name: fcn_hr18s_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_hr18s_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_hr18_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_hr48_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_hr18s_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_hr18_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_hr48_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_hr18s_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr18_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr48_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr48_4xb4-40k_pascal-context-480x480\n",
      "model_name: fcn_hr48_4xb4-80k_pascal-context-480x480\n",
      "model_name: fcn_hr48_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: fcn_hr48_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: fcn_hr18s_4xb4-80k_loveda-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_loveda-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_loveda-512x512\n",
      "model_name: fcn_hr18s_4xb4-80k_potsdam-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_potsdam-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_potsdam-512x512\n",
      "model_name: fcn_hr18s_4xb4-80k_vaihingen-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_vaihingen-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_vaihingen-512x512\n",
      "model_name: fcn_hr18s_4xb4-80k_isaid-896x896\n",
      "model_name: fcn_hr18_4xb4-80k_isaid-896x896\n",
      "model_name: fcn_hr48_4xb4-80k_isaid-896x896\n",
      "model_name: icnet_r18-d8_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r18-d8_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r18-d8-in1k-pre_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r18-d8-in1k-pre_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8-in1k-pre_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8-in1k-pre_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8-in1k-pre_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8-in1k-pre_4xb2-160k_cityscapes-832x832\n",
      "model_name: isanet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: isanet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: isanet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: isanet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: isanet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: isanet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: isanet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: isanet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: isanet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: isanet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: isanet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: isanet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: isanet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: isanet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: isanet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: isanet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: knet-s3_r50-d8_fcn_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_r50-d8_pspnet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_r50-d8_deeplabv3_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_r50-d8_upernet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_swin-t_upernet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_swin-l_upernet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_swin-l_upernet_8xb2-adamw-80k_ade20k-640x640\n",
      "model_name: mae-base_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: mask2former_r50_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_r101_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-t_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-s_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_r50_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_r101_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_swin-t_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_swin-s_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_ade20k-640x640\n",
      "model_name: mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640\n",
      "model_name: mask2former_swin-l-in22k-384x384-pre_8xb2-160k_ade20k-640x640\n",
      "model_name: maskformer_r50-d32_8xb2-160k_ade20k-512x512\n",
      "model_name: maskformer_r101-d32_8xb2-160k_ade20k-512x512\n",
      "model_name: maskformer_swin-t_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: maskformer_swin-s_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_fcn_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_pspnet_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_deeplabv3_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_deeplabv3plus_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_fcn_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_pspnet_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_deeplabv3_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_deeplabv3plus_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: mobilenet-v3-d8-scratch_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: mobilenet-v3-d8-s_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: mobilenet-v3-d8-scratch-s_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: nonlocal_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: nonlocal_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: nonlocal_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: nonlocal_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: nonlocal_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: nonlocal_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: nonlocal_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: nonlocal_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: nonlocal_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: nonlocal_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: nonlocal_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: nonlocal_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18s_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr48_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18s_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr48_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18s_4xb2-160k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18_4xb2-160k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr48_4xb2-160k_cityscapes-512x1024\n",
      "model_name: ocrnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_r101-d8_8xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_r101-d8_8xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18s_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr18_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr48_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr18s_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr18_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr48_4xb4-160k_ade20k-512x512\n",
      "model_name: ocrnet_hr18s_4xb4-20k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18_4xb4-20k_voc12aug-512x512\n",
      "model_name: ocrnet_hr48_4xb4-20k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18s_4xb4-40k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18_4xb4-40k_voc12aug-512x512\n",
      "model_name: ocrnet_hr48_4xb4-40k_voc12aug-512x512\n",
      "model_name: pidnet-s_2xb6-120k_1024x1024-cityscapes\n",
      "model_name: pidnet-m_2xb6-120k_1024x1024-cityscapes\n",
      "model_name: pidnet-l_2xb6-120k_1024x1024-cityscapes\n",
      "model_name: pointrend_r50_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pointrend_r101_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pointrend_r50_4xb4-160k_ade20k-512x512\n",
      "model_name: pointrend_r101_4xb4-160k_ade20k-512x512\n",
      "model_name: fpn_poolformer_s12_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_s24_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_s36_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_m36_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_m48_8xb4-40k_ade20k-512x512\n",
      "model_name: psanet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: psanet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: psanet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: psanet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: psanet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: psanet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: psanet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: psanet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: psanet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: psanet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: psanet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: psanet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: psanet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: psanet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: psanet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: psanet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: pspnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: pspnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: pspnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: pspnet_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8-rsb_4xb2-adamw-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r50b-d32_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d32_rsb_4xb2-adamw-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50b-d32_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: pspnet_r101-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: pspnet_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: pspnet_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: pspnet_r50-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_loveda-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_loveda-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_loveda-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_isaid-896x896\n",
      "model_name: pspnet_r50-d8_4xb4-80k_isaid-896x896\n",
      "model_name: resnest_s101-d8_fcn_4xb2-80k_cityscapes-512x1024\n",
      "model_name: resnest_s101-d8_pspnet_4xb2-80k_cityscapes512x1024\n",
      "model_name: resnest_s101-d8_deeplabv3_4xb2-80k_cityscapes-512x1024\n",
      "model_name: resnest_s101-d8_deeplabv3plus_4xb2-80k_cityscapes-512x1024\n",
      "model_name: resnest_s101-d8_fcn_4xb4-160k_ade20k-512x512\n",
      "model_name: resnest_s101-d8_pspnet_4xb4-160k_ade20k-512x512\n",
      "model_name: resnest_s101-d8_deeplabv3_4xb4-160k_ade20k-512x512\n",
      "model_name: resnest_s101-d8_deeplabv3plus_4xb4-160k_ade20k-512x512\n",
      "model_name: san-vit-b16_coco-stuff164k-640x640\n",
      "model_name: san-vit-l14_coco-stuff164k-640x640\n",
      "model_name: segformer_mit-b0_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b1_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b2_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b3_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b4_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b5_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b5_8xb2-160k_ade20k-640x640\n",
      "model_name: segformer_mit-b0_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b1_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b2_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b3_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b4_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b5_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segmenter_vit-t_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-s_fcn_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-s_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-b_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-l_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-t_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-s_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-b_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-l_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: fpn_r50_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fpn_r101_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fpn_r50_4xb4-160k_ade20k-512x512\n",
      "model_name: fpn_r101_4xb4-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_naive_8xb2-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_pup_8xb2-160k_ade20k-512x512\n",
      "model_name: setr_vit-l-mla_8xb1-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_mla_8xb2-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_naive_8xb1-80k_cityscapes-768x768\n",
      "model_name: setr_vit-l_pup_8xb1-80k_cityscapes-768x768\n",
      "model_name: setr_vit-l_mla_8xb1-80k_cityscapes-768x768\n",
      "model_name: stdc1_4xb12-80k_cityscapes-512x1024\n",
      "model_name: stdc1_in1k-pre_4xb12-80k_cityscapes-512x1024\n",
      "model_name: stdc2_4xb12-80k_cityscapes-512x1024\n",
      "model_name: stdc2_in1k-pre_4xb12-80k_cityscapes-512x1024\n",
      "model_name: swin-tiny-patch4-window7-in1k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-small-patch4-window7-in1k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window7-in1k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window7-in22k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window12-in22k-384x384-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_pcpvt-s_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-s_uperhead_8xb4-160k_ade20k-512x512\n",
      "model_name: twins_pcpvt-b_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-b_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_pcpvt-l_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-l_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_svt-s_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_svt-s_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_svt-b_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_svt-b_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_svt-l_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-l_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: unet-s5-d16_fcn_4xb4-160k_cityscapes-512x1024\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_drive-64x64\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_drive-64x64\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_drive-64x64\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_drive-64x64\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-40k_drive-64x64\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_drive-64x64\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_stare-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_stare-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_stare-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_stare-128x128\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-40k_stare-128x128\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_stare-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_chase-db1-128x128\n",
      "model_name: unet_s5-d16_deeplabv3_4xb4-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_hrf-256x256\n",
      "model_name: upernet_r50_4xb2-40k_cityscapes-512x1024\n",
      "model_name: upernet_r101_4xb2-40k_cityscapes-512x1024\n",
      "model_name: upernet_r50_4xb2-40k_cityscapes-769x769\n",
      "model_name: upernet_r101_4xb2-40k_cityscapes-769x769\n",
      "model_name: upernet_r50_4xb2-80k_cityscapes-512x1024\n",
      "model_name: upernet_r101_4xb2-80k_cityscapes-512x1024\n",
      "model_name: upernet_r50_4xb2-80k_cityscapes-769x769\n",
      "model_name: upernet_r101_4xb2-80k_cityscapes-769x769\n",
      "model_name: upernet_r50_4xb4-80k_ade20k-512x512\n",
      "model_name: upernet_r101_4xb4-80k_ade20k-512x512\n",
      "model_name: upernet_r50_4xb4-160k_ade20k-512x512\n",
      "model_name: upernet_r101_4xb4-160k_ade20k-512x512\n",
      "model_name: upernet_r50_4xb4-20k_voc12aug-512x512\n",
      "model_name: upernet_r101_4xb4-20k_voc12aug-512x512\n",
      "model_name: upernet_r50_4xb4-40k_voc12aug-512x512\n",
      "model_name: upernet_r101_4xb4-40k_voc12aug-512x512\n",
      "model_name: vit_vit-b16_mln_upernet_8xb2-80k_ade20k-512x512\n",
      "model_name: vit_vit-b16_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_vit-b16-ln_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-s16_upernet_8xb2-80k_ade20k-512x512\n",
      "model_name: vit_deit-s16_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-s16_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-s16-ln_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-b16_upernet_8xb2-80k_ade20k-512x512\n",
      "model_name: vit_deit-b16_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-b16_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-b16-ln_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vpd_sd_4xb8-25k_nyu-480x480\n",
      "model_name: vpd_sd_4xb8-25k_nyu-512x512\n",
      "model_name: v\n",
      "model_name: p\n",
      "model_name: d\n",
      "model_name: _\n",
      "model_name: d\n",
      "model_name: e\n",
      "model_name: p\n",
      "model_name: t\n",
      "model_name: h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import MMSegInferencer\n",
    "models = MMSegInferencer.list_models('mmseg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like nvidia/segformer-b0-finetuned-ade-512-512 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mtimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connectionpool.py:1096\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    610\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connection.py:212\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x0000022F7F1599A0>, 'Connection to huggingface.co timed out. (connect timeout=10)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\urllib3\\util\\retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /nvidia/segformer-b0-finetuned-ade-512-512/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000022F7F1599A0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\file_download.py:1238\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1238\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\file_download.py:1631\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1631\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 385\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\file_download.py:408\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:67\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\requests\\adapters.py:507\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[1;32m--> 507\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /nvidia/segformer-b0-finetuned-ade-512-512/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000022F7F1599A0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 48ea4596-69a0-4125-be3f-22f63c5e88a9)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\utils\\hub.py:389\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\huggingface_hub\\file_download.py:1371\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[0;32m   1372\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhead_call_error\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;66;03m# From now on, etag and commit_hash are not None.\u001b[39;00m\n",
      "\u001b[1;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SegformerForSemanticSegmentation\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomImageDataset\n\u001b[1;32m----> 9\u001b[0m segmodel \u001b[38;5;241m=\u001b[39m \u001b[43mSegformerForSemanticSegmentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnvidia/segformer-b0-finetuned-ade-512-512\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#id2label=self.id2label,\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#label2id=self.label2id,\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     \u001b[39;00m\n\u001b[0;32m     19\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m SegformerFeatureExtractor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvidia/segformer-b0-finetuned-ade-512-512\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\modeling_utils.py:2942\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   2941\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[1;32m-> 2942\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2952\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2953\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_auto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_auto_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2955\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2958\u001b[0m     \u001b[38;5;66;03m# In case one passes a config to `from_pretrained` + \"attn_implementation\"\u001b[39;00m\n\u001b[0;32m   2959\u001b[0m     \u001b[38;5;66;03m# override the `_attn_implementation` attribute to `attn_implementation` of the kwargs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2963\u001b[0m     \u001b[38;5;66;03m# we pop attn_implementation from the kwargs but this handles the case where users\u001b[39;00m\n\u001b[0;32m   2964\u001b[0m     \u001b[38;5;66;03m# passes manually the config to `from_pretrained`.\u001b[39;00m\n\u001b[0;32m   2965\u001b[0m     config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\configuration_utils.py:615\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[0;32m    611\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[1;32m--> 615\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m    617\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    620\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\configuration_utils.py:644\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    646\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\configuration_utils.py:699\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 699\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\utils\\hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this file, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[1;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like nvidia/segformer-b0-finetuned-ade-512-512 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import SegformerFeatureExtractor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from dataset import CustomImageDataset\n",
    "\n",
    "segmodel = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b0-finetuned-ade-512-512\", \n",
    "            return_dict=False, \n",
    "            num_labels=4,\n",
    "            #id2label=self.id2label,\n",
    "            #label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "#     \n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "feature_extractor.reduce_labels = False\n",
    "feature_extractor.size = 128\n",
    "\n",
    "local_data_path = 'C:\\Workspace\\Personal\\ccp_data/Training/image/AP10_City_IMAGE'\n",
    "server_data_path = '/mnt/nas27_dataset/Dataset/ccp/Training/image/AP10_City_IMAGE/'\n",
    "colab_data_path = '/content/gdrive/MyDrive/ColabNotebooks/ViT/Training/image/SN10_Forest_IMAGE'\n",
    "\n",
    "# Fine-tuning    \n",
    "train_dataset = CustomImageDataset(folder_path=colab_data_path, transform=None, mode=\"Train\")\n",
    "valid_dataset = CustomImageDataset(folder_path=colab_data_path, transform=None, mode=\"Valid\")\n",
    "\n",
    "#   \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "#  fine-tuning  Trainer  TrainingArguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=1,  # 1 epoch \n",
    "    per_device_train_batch_size=8,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=segmodel,\n",
    "    args=training_args,\n",
    "    data_collator=None,  #    collate_fn  (: default_data_collator)\n",
    "    train_dataset=train_dataloader,\n",
    ")\n",
    "\n",
    "#  \n",
    "trainer.train()\n",
    "\n",
    "#   \n",
    "trainer.save_model(\"./fine_tuned_segformer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'distutils' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SegformerForSemanticSegmentation\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_metric\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m _PROJECT_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(_PACKAGE_ROOT)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\callbacks\\__init__.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprediction_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePredictionWriter\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprogress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProgressBar, ProgressBarBase\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpruning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelPruning\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantizationAwareTraining\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_weight_avg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticWeightAveraging\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\callbacks\\pruning.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningModule\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_to_collection\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rank_zero_debug, rank_zero_only\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\core\\__init__.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningModule\n\u001b[0;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightningDataModule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningOptimizer\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelIO\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx_validator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FxValidator\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rank_zero_deprecation, rank_zero_warn\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_to_collection, convert_to_tensors\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggerConnector  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m memory\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningLoggerBase, LoggerCollection, TensorBoardLogger\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _METRIC, MetricSource\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunningStage, TrainerFn\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\loggers\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningLoggerBase, LoggerCollection\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv_logs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSVLogger\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoardLogger\n\u001b[0;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightningLoggerBase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoggerCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorBoardLogger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSVLogger\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _COMET_AVAILABLE, CometLogger  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\loggers\\tensorboard.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Optional, Union\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hparams\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msetuptools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distutils\n\u001b[1;32m----> 4\u001b[0m LooseVersion \u001b[38;5;241m=\u001b[39m \u001b[43mdistutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mLooseVersion\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensorboard, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m LooseVersion(tensorboard\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m LooseVersion(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.15\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorBoard logging requires TensorBoard version 1.15 or above\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'distutils' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from datasets import load_metric\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class SegformerFinetuner(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(SegformerFinetuner, self).__init__()\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "        \n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v:k for k,v in self.id2label.items()}\n",
    "        \n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b0-finetuned-ade-512-512\", \n",
    "            return_dict=False, \n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "        \n",
    "        self.train_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.val_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.test_mean_iou = load_metric(\"mean_iou\")\n",
    "        \n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return(outputs)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        \n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.train_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "\n",
    "            metrics = self.train_mean_iou.compute(\n",
    "                num_labels=self.num_classes, \n",
    "                ignore_index=255, \n",
    "                reduce_labels=False,\n",
    "            )\n",
    "            \n",
    "            metrics = {'loss': loss, \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"]}\n",
    "            \n",
    "            for k,v in metrics.items():\n",
    "                self.log(k,v)\n",
    "            \n",
    "            return(metrics)\n",
    "        else:\n",
    "            return({'loss': loss})\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        \n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "        self.val_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        \n",
    "        return({'val_loss': loss})\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        metrics = self.val_mean_iou.compute(\n",
    "              num_labels=self.num_classes, \n",
    "              ignore_index=255, \n",
    "              reduce_labels=False,\n",
    "          )\n",
    "        \n",
    "        avg_val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        val_mean_iou = metrics[\"mean_iou\"]\n",
    "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        \n",
    "        metrics = {\"val_loss\": avg_val_loss, \"val_mean_iou\":val_mean_iou, \"val_mean_accuracy\":val_mean_accuracy}\n",
    "        for k,v in metrics.items():\n",
    "            self.log(k,v)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    # def test_step(self, batch, batch_nb):\n",
    "        \n",
    "    #     images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "    #     outputs = self(images, masks)\n",
    "        \n",
    "    #     loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "    #     upsampled_logits = nn.functional.interpolate(\n",
    "    #         logits, \n",
    "    #         size=masks.shape[-2:], \n",
    "    #         mode=\"bilinear\", \n",
    "    #         align_corners=False\n",
    "    #     )\n",
    "        \n",
    "    #     predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "    #     self.test_mean_iou.add_batch(\n",
    "    #         predictions=predicted.detach().cpu().numpy(), \n",
    "    #         references=masks.detach().cpu().numpy()\n",
    "    #     )\n",
    "            \n",
    "    #     return({'test_loss': loss})\n",
    "    \n",
    "    # def test_epoch_end(self, outputs):\n",
    "    #     metrics = self.test_mean_iou.compute(\n",
    "    #           num_labels=self.num_classes, \n",
    "    #           ignore_index=255, \n",
    "    #           reduce_labels=False,\n",
    "    #       )\n",
    "       \n",
    "    #     avg_test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "    #     test_mean_iou = metrics[\"mean_iou\"]\n",
    "    #     test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "\n",
    "    #      metrics = {\"test_loss\": avg_test_loss, \"test_mean_iou\":test_mean_iou, \"test_mean_accuracy\":test_mean_accuracy}\n",
    "        \n",
    "    #     for k,v in metrics.items():\n",
    "    #         self.log(k,v)\n",
    "        \n",
    "    #     return metrics\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "    \n",
    "    # def test_dataloader(self):\n",
    "    #     return self.test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segformer_finetuner = SegformerFinetuner(\n",
    "    train_dataset.id2label, \n",
    "    train_dataloader=train_dataloader, \n",
    "    val_dataloader=valid_dataloader, \n",
    "    #test_dataloader=test_dataloader, \n",
    "    metrics_interval=10,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    min_delta=0.00, \n",
    "    patience=3, \n",
    "    verbose=False, \n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    max_epochs=500,\n",
    "    val_check_interval=len(train_dataloader),\n",
    ")\n",
    "\n",
    "trainer.fit(segformer_finetuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Fine-tuning  Trainer  TrainingArguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./your_output_directory\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=feature_extractor,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataloader,\n",
    "    eval_dataset=valid_dataloader,\n",
    ")\n",
    "\n",
    "# Fine-tuning \n",
    "trainer.train()\n",
    "'''\n",
    "\n",
    "class TrainerCustom(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        labels = inputs.get(\"labels\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Fine-tuning  Trainer  TrainingArguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./your_output_directory\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = TrainerCustom(\n",
    "    model=feature_extractor,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataloader,\n",
    "    eval_dataset=valid_dataloader,\n",
    ")\n",
    "\n",
    "# Fine-tuning \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_IMAGE Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_SH Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_Carbon Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_GT Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_IMAGE Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_SH Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_Carbon Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_GT Done.\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import SegformerFeatureExtractor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from dataset import CustomImageDataset\n",
    "\n",
    "local_data_path = 'C:\\Workspace\\Personal\\ccp_data/Training/image/AP10_City_IMAGE'\n",
    "server_data_path = '/mnt/nas27_dataset/Dataset/ccp/Training/image/AP10_City_IMAGE/'\n",
    "home_data_path = 'C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_IMAGE'\n",
    "\n",
    "# Fine-tuning    \n",
    "train_dataset = CustomImageDataset(folder_path=home_data_path, transform=None, mode=\"Train\")\n",
    "valid_dataset = CustomImageDataset(folder_path=home_data_path, transform=None, mode=\"Valid\")\n",
    "\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "\n",
    "#for i in range(min(5, len(train_dataset))):\n",
    "    #sample = train_dataset[i]\n",
    "    #print(sample)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basiccuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

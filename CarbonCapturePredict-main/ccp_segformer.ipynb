{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/13 16:40:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - model_name: ann_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ann_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ann_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ann_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ann_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ann_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ann_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ann_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ann_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ann_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ann_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ann_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ann_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ann_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ann_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ann_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: apcnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: apcnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: apcnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: apcnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: apcnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: apcnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: apcnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: apcnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: apcnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: apcnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: apcnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: apcnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: beit-base_upernet_8xb2-160k_ade20k-640x640\n",
      "model_name: beit-large_upernet_8xb1-amp-160k_ade20k-640x640\n",
      "model_name: bisenetv1_r18-d32_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r18-d32-in1k-pre_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r18-d32-in1k-pre_4xb8-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r50-d32_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r50-d32-in1k-pre_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv1_r18-d32_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r18-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r50-d32_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r50-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r50-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv1_r101-d32-in1k-pre_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: bisenetv2_fcn_4xb4-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv2_fcn_4xb4-ohem-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv2_fcn_4xb8-160k_cityscapes-1024x1024\n",
      "model_name: bisenetv2_fcn_4xb4-amp-160k_cityscapes-1024x1024\n",
      "model_name: ccnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ccnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ccnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ccnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: ccnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ccnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ccnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ccnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ccnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: ccnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: ccnet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: ccnet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ccnet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: cgnet_fcn_4xb4-60k_cityscapes-680x680\n",
      "model_name: cgnet_fcn_4xb8-60k_cityscapes-512x1024\n",
      "model_name: convnext-tiny_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: convnext-small_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: convnext-base_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: convnext-base_upernet_8xb2-amp-160k_ade20k-640x640\n",
      "model_name: convnext-large_upernet_8xb2-amp-160k_ade20k-640x640\n",
      "model_name: convnext-xlarge_upernet_8xb2-amp-160k_ade20k-640x640\n",
      "model_name: danet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: danet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: danet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: danet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: danet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: danet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: danet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: danet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: danet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: danet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: danet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: danet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: danet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: danet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: danet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: danet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ddrnet_23-slim_in1k-pre_2xb6-120k_cityscapes-1024x1024\n",
      "model_name: ddrnet_23_in1k-pre_2xb6-120k_cityscapes-1024x1024\n",
      "model_name: deeplabv3_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101-d16-mg124_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101-d16-mg124_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: deeplabv3_r50-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r50-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3_r101-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: ddeeplabv3plus_r101-d16-mg124_4xb2-40k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101-d16-mg124_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: deeplabv3plus_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_loveda-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_loveda-512x512\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: deeplabv3plus_r101-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: deeplabv3plus_r18-d8_4xb4-80k_isaid-896x896\n",
      "model_name: deeplabv3plus_r50-d8_4xb4-80k_isaid-896x896\n",
      "model_name: deeplabv3plus_r50-d8_4xb2-300k_mapillay_v1_65-1280x1280\n",
      "model_name: dmnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dmnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dmnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dmnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dmnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dmnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dmnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dmnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dmnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dmnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dmnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dmnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dnl_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dnl_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: dnl_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dnl_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: dnl_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dnl_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: dnl_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dnl_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: dnl_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dnl_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: dnl_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dnl_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: dpt_vit-b16_8xb2-160k_ade20k-512x512\n",
      "model_name: eemanet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: emanet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: emanet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: emanet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: encnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: encnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: encnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: encnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: encnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: encnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: encnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: encnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: encnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: encnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: encnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: encnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: erfnet_fcn_4xb4-160k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb4-80k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_aspp_4xb4-160k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb4-80k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_psp_4xb4-160k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb4-80k_ade20k-512x512\n",
      "model_name: fastfcn_r50-d32_jpu_enc_4xb4-160k_ade20k-512x512\n",
      "model_name: fast_scnn_8xb4-160k_cityscapes-512x1024\n",
      "model_name: fcn_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: fcn_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r50-d16_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r50-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r50-d16_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn-d6_r50-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r101-d16_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r101-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r101-d16_4xb2-40k_cityscapes-769x769\n",
      "model_name: fcn-d6_r101-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r50b-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r50b-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn-d6_r101b-d16_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn-d6_r101b-d16_4xb2-80k_cityscapes-769x769\n",
      "model_name: fcn_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_r101-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: fcn_r101-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: fcn_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: fcn_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: gcnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: gcnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: gcnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: gcnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: gcnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: gcnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: gcnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: gcnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: gcnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: gcnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: gcnet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: gcnet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: gcnet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr18s_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_hr18_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_hr48_4xb2-40k_cityscapes-512x1024\n",
      "model_name: fcn_hr18s_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_hr18_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_hr48_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fcn_hr18s_4xb2-160k_cityscapes-512x1024\n",
      "model_name: fcn_hr18_4xb2-160k_cityscapes-512x1024\n",
      "model_name: fcn_hr48_4xb2-160k_cityscapes-512x1024\n",
      "model_name: fcn_hr18s_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_ade20k-512x512\n",
      "model_name: fcn_hr18s_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_hr18_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_hr48_4xb4-160k_ade20k-512x512\n",
      "model_name: fcn_hr18s_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_hr18_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_hr48_4xb4-20k_voc12aug-512x512\n",
      "model_name: fcn_hr18s_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr18_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr48_4xb4-40k_voc12aug-512x512\n",
      "model_name: fcn_hr48_4xb4-40k_pascal-context-480x480\n",
      "model_name: fcn_hr48_4xb4-80k_pascal-context-480x480\n",
      "model_name: fcn_hr48_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: fcn_hr48_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: fcn_hr18s_4xb4-80k_loveda-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_loveda-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_loveda-512x512\n",
      "model_name: fcn_hr18s_4xb4-80k_potsdam-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_potsdam-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_potsdam-512x512\n",
      "model_name: fcn_hr18s_4xb4-80k_vaihingen-512x512\n",
      "model_name: fcn_hr18_4xb4-80k_vaihingen-512x512\n",
      "model_name: fcn_hr48_4xb4-80k_vaihingen-512x512\n",
      "model_name: fcn_hr18s_4xb4-80k_isaid-896x896\n",
      "model_name: fcn_hr18_4xb4-80k_isaid-896x896\n",
      "model_name: fcn_hr48_4xb4-80k_isaid-896x896\n",
      "model_name: icnet_r18-d8_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r18-d8_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r18-d8-in1k-pre_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r18-d8-in1k-pre_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8-in1k-pre_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r50-d8-in1k-pre_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8_4xb2-160k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8-in1k-pre_4xb2-80k_cityscapes-832x832\n",
      "model_name: icnet_r101-d8-in1k-pre_4xb2-160k_cityscapes-832x832\n",
      "model_name: isanet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: isanet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: isanet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: isanet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: isanet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: isanet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: isanet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: isanet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: isanet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: isanet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: isanet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: isanet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: isanet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: isanet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: isanet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: isanet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: knet-s3_r50-d8_fcn_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_r50-d8_pspnet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_r50-d8_deeplabv3_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_r50-d8_upernet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_swin-t_upernet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_swin-l_upernet_8xb2-adamw-80k_ade20k-512x512\n",
      "model_name: knet-s3_swin-l_upernet_8xb2-adamw-80k_ade20k-640x640\n",
      "model_name: mae-base_upernet_8xb2-amp-160k_ade20k-512x512\n",
      "model_name: mask2former_r50_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_r101_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-t_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-s_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024\n",
      "model_name: mask2former_r50_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_r101_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_swin-t_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_swin-s_8xb2-160k_ade20k-512x512\n",
      "model_name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_ade20k-640x640\n",
      "model_name: mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640\n",
      "model_name: mask2former_swin-l-in22k-384x384-pre_8xb2-160k_ade20k-640x640\n",
      "model_name: maskformer_r50-d32_8xb2-160k_ade20k-512x512\n",
      "model_name: maskformer_r101-d32_8xb2-160k_ade20k-512x512\n",
      "model_name: maskformer_swin-t_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: maskformer_swin-s_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_fcn_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_pspnet_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_deeplabv3_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_deeplabv3plus_4xb2-80k_cityscapes-512x1024\n",
      "model_name: mobilenet-v2-d8_fcn_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_pspnet_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_deeplabv3_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v2-d8_deeplabv3plus_4xb4-160k_ade20k-512x512\n",
      "model_name: mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: mobilenet-v3-d8-scratch_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: mobilenet-v3-d8-s_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: mobilenet-v3-d8-scratch-s_lraspp_4xb4-320k_cityscapes-512x1024\n",
      "model_name: nonlocal_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: nonlocal_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: nonlocal_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: nonlocal_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: nonlocal_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: nonlocal_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: nonlocal_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: nonlocal_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: nonlocal_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: nonlocal_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: nonlocal_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: nonlocal_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: nonlocal_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18s_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr48_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18s_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr48_4xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18s_4xb2-160k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18_4xb2-160k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr48_4xb2-160k_cityscapes-512x1024\n",
      "model_name: ocrnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_r101-d8_8xb2-40k_cityscapes-512x1024\n",
      "model_name: ocrnet_r101-d8_8xb2-80k_cityscapes-512x1024\n",
      "model_name: ocrnet_hr18s_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr18_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr48_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr18s_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr18_4xb4-80k_ade20k-512x512\n",
      "model_name: ocrnet_hr48_4xb4-160k_ade20k-512x512\n",
      "model_name: ocrnet_hr18s_4xb4-20k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18_4xb4-20k_voc12aug-512x512\n",
      "model_name: ocrnet_hr48_4xb4-20k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18s_4xb4-40k_voc12aug-512x512\n",
      "model_name: ocrnet_hr18_4xb4-40k_voc12aug-512x512\n",
      "model_name: ocrnet_hr48_4xb4-40k_voc12aug-512x512\n",
      "model_name: pidnet-s_2xb6-120k_1024x1024-cityscapes\n",
      "model_name: pidnet-m_2xb6-120k_1024x1024-cityscapes\n",
      "model_name: pidnet-l_2xb6-120k_1024x1024-cityscapes\n",
      "model_name: pointrend_r50_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pointrend_r101_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pointrend_r50_4xb4-160k_ade20k-512x512\n",
      "model_name: pointrend_r101_4xb4-160k_ade20k-512x512\n",
      "model_name: fpn_poolformer_s12_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_s24_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_s36_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_m36_8xb4-40k_ade20k-512x512\n",
      "model_name: fpn_poolformer_m48_8xb4-40k_ade20k-512x512\n",
      "model_name: psanet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: psanet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: psanet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: psanet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: psanet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: psanet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: psanet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: psanet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: psanet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: psanet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: psanet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: psanet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: psanet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: psanet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: psanet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: psanet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: pspnet_r50-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: pspnet_r101-d8_4xb2-40k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: pspnet_r101-d8_4xb2-40k_cityscapes-769x769\n",
      "model_name: pspnet_r18-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8-rsb_4xb2-adamw-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r101-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r101-d8_4xb2-amp-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r18-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r50-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r101-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r18b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r101b-d8_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r18b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r50b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r101b-d8_4xb2-80k_cityscapes-769x769\n",
      "model_name: pspnet_r50b-d32_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d32_rsb_4xb2-adamw-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50b-d32_4xb2-80k_cityscapes-512x1024\n",
      "model_name: pspnet_r50-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_ade20k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-160k_ade20k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-20k_voc12aug-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-40k_voc12aug-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-40k_pascal-context-480x480\n",
      "model_name: pspnet_r101-d8_4xb4-80k_pascal-context-480x480\n",
      "model_name: pspnet_r101-d8_4xb4-40k_pascal-context-59-480x480\n",
      "model_name: pspnet_r101-d8_4xb4-80k_pascal-context-59-480x480\n",
      "model_name: pspnet_r50-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-20k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-40k_coco-stuff10k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-160k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-320k_coco-stuff164k-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_loveda-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_loveda-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_loveda-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_potsdam-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: pspnet_r50-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: pspnet_r101-d8_4xb4-80k_vaihingen-512x512\n",
      "model_name: pspnet_r18-d8_4xb4-80k_isaid-896x896\n",
      "model_name: pspnet_r50-d8_4xb4-80k_isaid-896x896\n",
      "model_name: resnest_s101-d8_fcn_4xb2-80k_cityscapes-512x1024\n",
      "model_name: resnest_s101-d8_pspnet_4xb2-80k_cityscapes512x1024\n",
      "model_name: resnest_s101-d8_deeplabv3_4xb2-80k_cityscapes-512x1024\n",
      "model_name: resnest_s101-d8_deeplabv3plus_4xb2-80k_cityscapes-512x1024\n",
      "model_name: resnest_s101-d8_fcn_4xb4-160k_ade20k-512x512\n",
      "model_name: resnest_s101-d8_pspnet_4xb4-160k_ade20k-512x512\n",
      "model_name: resnest_s101-d8_deeplabv3_4xb4-160k_ade20k-512x512\n",
      "model_name: resnest_s101-d8_deeplabv3plus_4xb4-160k_ade20k-512x512\n",
      "model_name: san-vit-b16_coco-stuff164k-640x640\n",
      "model_name: san-vit-l14_coco-stuff164k-640x640\n",
      "model_name: segformer_mit-b0_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b1_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b2_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b3_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b4_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b5_8xb2-160k_ade20k-512x512\n",
      "model_name: segformer_mit-b5_8xb2-160k_ade20k-640x640\n",
      "model_name: segformer_mit-b0_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b1_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b2_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b3_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b4_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segformer_mit-b5_8xb1-160k_cityscapes-1024x1024\n",
      "model_name: segmenter_vit-t_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-s_fcn_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-s_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-b_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segmenter_vit-l_mask_8xb1-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-t_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-s_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-b_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: segnext_mscan-l_1xb16-adamw-160k_ade20k-512x512\n",
      "model_name: fpn_r50_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fpn_r101_4xb2-80k_cityscapes-512x1024\n",
      "model_name: fpn_r50_4xb4-160k_ade20k-512x512\n",
      "model_name: fpn_r101_4xb4-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_naive_8xb2-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_pup_8xb2-160k_ade20k-512x512\n",
      "model_name: setr_vit-l-mla_8xb1-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_mla_8xb2-160k_ade20k-512x512\n",
      "model_name: setr_vit-l_naive_8xb1-80k_cityscapes-768x768\n",
      "model_name: setr_vit-l_pup_8xb1-80k_cityscapes-768x768\n",
      "model_name: setr_vit-l_mla_8xb1-80k_cityscapes-768x768\n",
      "model_name: stdc1_4xb12-80k_cityscapes-512x1024\n",
      "model_name: stdc1_in1k-pre_4xb12-80k_cityscapes-512x1024\n",
      "model_name: stdc2_4xb12-80k_cityscapes-512x1024\n",
      "model_name: stdc2_in1k-pre_4xb12-80k_cityscapes-512x1024\n",
      "model_name: swin-tiny-patch4-window7-in1k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-small-patch4-window7-in1k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window7-in1k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window7-in22k-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: swin-base-patch4-window12-in22k-384x384-pre_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_pcpvt-s_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-s_uperhead_8xb4-160k_ade20k-512x512\n",
      "model_name: twins_pcpvt-b_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-b_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_pcpvt-l_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-l_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_svt-s_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_svt-s_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_svt-b_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_svt-b_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: twins_svt-l_fpn_fpnhead_8xb4-80k_ade20k-512x512\n",
      "model_name: twins_pcpvt-l_uperhead_8xb2-160k_ade20k-512x512\n",
      "model_name: unet-s5-d16_fcn_4xb4-160k_cityscapes-512x1024\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_drive-64x64\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_drive-64x64\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_drive-64x64\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_drive-64x64\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-40k_drive-64x64\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_drive-64x64\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_stare-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_stare-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_stare-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_stare-128x128\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-40k_stare-128x128\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_stare-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_chase-db1-128x128\n",
      "model_name: unet_s5-d16_deeplabv3_4xb4-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_chase-db1-128x128\n",
      "model_name: unet-s5-d16_fcn_4xb4-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_fcn_4xb4-ce-1.0-dice-3.0-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_pspnet_4xb4-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_pspnet_4xb4-ce-1.0-dice-3.0-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256\n",
      "model_name: unet-s5-d16_deeplabv3_4xb4-ce-1.0-dice-3.0-40k_hrf-256x256\n",
      "model_name: upernet_r50_4xb2-40k_cityscapes-512x1024\n",
      "model_name: upernet_r101_4xb2-40k_cityscapes-512x1024\n",
      "model_name: upernet_r50_4xb2-40k_cityscapes-769x769\n",
      "model_name: upernet_r101_4xb2-40k_cityscapes-769x769\n",
      "model_name: upernet_r50_4xb2-80k_cityscapes-512x1024\n",
      "model_name: upernet_r101_4xb2-80k_cityscapes-512x1024\n",
      "model_name: upernet_r50_4xb2-80k_cityscapes-769x769\n",
      "model_name: upernet_r101_4xb2-80k_cityscapes-769x769\n",
      "model_name: upernet_r50_4xb4-80k_ade20k-512x512\n",
      "model_name: upernet_r101_4xb4-80k_ade20k-512x512\n",
      "model_name: upernet_r50_4xb4-160k_ade20k-512x512\n",
      "model_name: upernet_r101_4xb4-160k_ade20k-512x512\n",
      "model_name: upernet_r50_4xb4-20k_voc12aug-512x512\n",
      "model_name: upernet_r101_4xb4-20k_voc12aug-512x512\n",
      "model_name: upernet_r50_4xb4-40k_voc12aug-512x512\n",
      "model_name: upernet_r101_4xb4-40k_voc12aug-512x512\n",
      "model_name: vit_vit-b16_mln_upernet_8xb2-80k_ade20k-512x512\n",
      "model_name: vit_vit-b16_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_vit-b16-ln_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-s16_upernet_8xb2-80k_ade20k-512x512\n",
      "model_name: vit_deit-s16_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-s16_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-s16-ln_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-b16_upernet_8xb2-80k_ade20k-512x512\n",
      "model_name: vit_deit-b16_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-b16_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vit_deit-b16-ln_mln_upernet_8xb2-160k_ade20k-512x512\n",
      "model_name: vpd_sd_4xb8-25k_nyu-480x480\n",
      "model_name: vpd_sd_4xb8-25k_nyu-512x512\n",
      "model_name: v\n",
      "model_name: p\n",
      "model_name: d\n",
      "model_name: _\n",
      "model_name: d\n",
      "model_name: e\n",
      "model_name: p\n",
      "model_name: t\n",
      "model_name: h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import MMSegInferencer\n",
    "models = MMSegInferencer.list_models('mmseg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([3, 256, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\segformer\\feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:101: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Workspace\\Personal\\ccp_data/Training/image/AP10_City_IMAGE Done.\n",
      "C:\\Workspace\\Personal\\ccp_data/Training/image/AP10_City_SH Done.\n",
      "C:\\Workspace\\Personal\\ccp_data/Training/label/AP10_City_Carbon Done.\n",
      "C:\\Workspace\\Personal\\ccp_data/Training/label/AP10_City_GT Done.\n",
      "C:\\Workspace\\Personal\\ccp_data/Validation/image/AP10_City_IMAGE Done.\n",
      "C:\\Workspace\\Personal\\ccp_data/Validation/image/AP10_City_SH Done.\n",
      "C:\\Workspace\\Personal\\ccp_data/Validation/label/AP10_City_Carbon Done.\n",
      "C:\\Workspace\\Personal\\ccp_data/Validation/label/AP10_City_GT Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m\n\u001b[0;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     45\u001b[0m     model\u001b[38;5;241m=\u001b[39msegmodel,\n\u001b[0;32m     46\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     47\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# 데이터셋에 따라 적절한 collate_fn 사용 (예: default_data_collator)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# 학습 수행\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 학습된 모델 저장\u001b[39;00m\n\u001b[0;32m     55\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine_tuned_segformer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\trainer.py:1821\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1820\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1821\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1822\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\accelerate\\data_loader.py:448\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 448\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\trainer_utils.py:772\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[\u001b[38;5;28mdict\u001b[39m]):\n\u001b[0;32m    771\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_columns(feature) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m--> 772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\data\\data_collator.py:70\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[1;34m(features, return_tensors)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# have the same attributes.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# on the whole batch.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_default_data_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\data\\data_collator.py:109\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features[\u001b[38;5;241m0\u001b[39m], Mapping):\n\u001b[1;32m--> 109\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mvars\u001b[39m(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m    110\u001b[0m first \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    111\u001b[0m batch \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\data\\data_collator.py:109\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features[\u001b[38;5;241m0\u001b[39m], Mapping):\n\u001b[1;32m--> 109\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m    110\u001b[0m first \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    111\u001b[0m batch \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import SegformerFeatureExtractor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from dataset import CustomImageDataset\n",
    "\n",
    "segmodel = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b0-finetuned-ade-512-512\", \n",
    "            return_dict=False, \n",
    "            num_labels=4,\n",
    "            #id2label=self.id2label,\n",
    "            #label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "# 모델 및 피쳐 추출기 로드\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "feature_extractor.reduce_labels = False\n",
    "feature_extractor.size = 128\n",
    "\n",
    "local_data_path = 'C:\\Workspace\\Personal\\ccp_data/Training/image/AP10_City_IMAGE'\n",
    "server_data_path = '/mnt/nas27_dataset/Dataset/ccp/Training/image/AP10_City_IMAGE/'\n",
    "colab_data_path = '/content/gdrive/MyDrive/ColabNotebooks/ViT/Training/image/SN10_Forest_IMAGE'\n",
    "\n",
    "# Fine-tuning에 사용할 데이터셋 클래스 초기화\n",
    "train_dataset = CustomImageDataset(folder_path=local_data_path, transform=None, mode=\"Train\")\n",
    "valid_dataset = CustomImageDataset(folder_path=local_data_path, transform=None, mode=\"Valid\")\n",
    "\n",
    "# # 데이터 로더 설정\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 모델을 fine-tuning하기 위한 Trainer 및 TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=1,  # 1 epoch만 학습\n",
    "    per_device_train_batch_size=8,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=segmodel,\n",
    "    args=training_args,\n",
    "    data_collator=None,  # 데이터셋에 따라 적절한 collate_fn 사용 (예: default_data_collator)\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# 학습 수행\n",
    "trainer.train()\n",
    "\n",
    "# 학습된 모델 저장\n",
    "trainer.save_model(\"./fine_tuned_segformer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'distutils' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SegformerForSemanticSegmentation\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_metric\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m _PROJECT_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(_PACKAGE_ROOT)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\callbacks\\__init__.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprediction_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePredictionWriter\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprogress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProgressBar, ProgressBarBase\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpruning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelPruning\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantizationAwareTraining\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_weight_avg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticWeightAveraging\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\callbacks\\pruning.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningModule\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_to_collection\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rank_zero_debug, rank_zero_only\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\core\\__init__.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningModule\n\u001b[0;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightningDataModule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py:41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningOptimizer\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelIO\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx_validator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FxValidator\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rank_zero_deprecation, rank_zero_warn\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_to_collection, convert_to_tensors\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggerConnector  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m memory\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningLoggerBase, LoggerCollection, TensorBoardLogger\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger_connector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _METRIC, MetricSource\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunningStage, TrainerFn\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\loggers\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningLoggerBase, LoggerCollection\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv_logs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSVLogger\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoardLogger\n\u001b[0;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightningLoggerBase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoggerCollection\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorBoardLogger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSVLogger\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _COMET_AVAILABLE, CometLogger  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\pytorch_lightning\\loggers\\tensorboard.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Optional, Union\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hparams\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LBW\\anaconda3\\envs\\basiccuda\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msetuptools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distutils\n\u001b[1;32m----> 4\u001b[0m LooseVersion \u001b[38;5;241m=\u001b[39m \u001b[43mdistutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mLooseVersion\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensorboard, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m LooseVersion(tensorboard\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m LooseVersion(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.15\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorBoard logging requires TensorBoard version 1.15 or above\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'distutils' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from datasets import load_metric\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class SegformerFinetuner(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(SegformerFinetuner, self).__init__()\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "        \n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v:k for k,v in self.id2label.items()}\n",
    "        \n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b0-finetuned-ade-512-512\", \n",
    "            return_dict=False, \n",
    "            num_labels=self.num_classes,\n",
    "            id2label=self.id2label,\n",
    "            label2id=self.label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "        \n",
    "        self.train_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.val_mean_iou = load_metric(\"mean_iou\")\n",
    "        self.test_mean_iou = load_metric(\"mean_iou\")\n",
    "        \n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return(outputs)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        \n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "        self.train_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "\n",
    "            metrics = self.train_mean_iou.compute(\n",
    "                num_labels=self.num_classes, \n",
    "                ignore_index=255, \n",
    "                reduce_labels=False,\n",
    "            )\n",
    "            \n",
    "            metrics = {'loss': loss, \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"]}\n",
    "            \n",
    "            for k,v in metrics.items():\n",
    "                self.log(k,v)\n",
    "            \n",
    "            return(metrics)\n",
    "        else:\n",
    "            return({'loss': loss})\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        \n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "        outputs = self(images, masks)\n",
    "        \n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, \n",
    "            size=masks.shape[-2:], \n",
    "            mode=\"bilinear\", \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "        self.val_mean_iou.add_batch(\n",
    "            predictions=predicted.detach().cpu().numpy(), \n",
    "            references=masks.detach().cpu().numpy()\n",
    "        )\n",
    "        \n",
    "        return({'val_loss': loss})\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        metrics = self.val_mean_iou.compute(\n",
    "              num_labels=self.num_classes, \n",
    "              ignore_index=255, \n",
    "              reduce_labels=False,\n",
    "          )\n",
    "        \n",
    "        avg_val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        val_mean_iou = metrics[\"mean_iou\"]\n",
    "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "        \n",
    "        metrics = {\"val_loss\": avg_val_loss, \"val_mean_iou\":val_mean_iou, \"val_mean_accuracy\":val_mean_accuracy}\n",
    "        for k,v in metrics.items():\n",
    "            self.log(k,v)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    # def test_step(self, batch, batch_nb):\n",
    "        \n",
    "    #     images, masks = batch['pixel_values'], batch['labels']\n",
    "        \n",
    "    #     outputs = self(images, masks)\n",
    "        \n",
    "    #     loss, logits = outputs[0], outputs[1]\n",
    "        \n",
    "    #     upsampled_logits = nn.functional.interpolate(\n",
    "    #         logits, \n",
    "    #         size=masks.shape[-2:], \n",
    "    #         mode=\"bilinear\", \n",
    "    #         align_corners=False\n",
    "    #     )\n",
    "        \n",
    "    #     predicted = upsampled_logits.argmax(dim=1)\n",
    "        \n",
    "    #     self.test_mean_iou.add_batch(\n",
    "    #         predictions=predicted.detach().cpu().numpy(), \n",
    "    #         references=masks.detach().cpu().numpy()\n",
    "    #     )\n",
    "            \n",
    "    #     return({'test_loss': loss})\n",
    "    \n",
    "    # def test_epoch_end(self, outputs):\n",
    "    #     metrics = self.test_mean_iou.compute(\n",
    "    #           num_labels=self.num_classes, \n",
    "    #           ignore_index=255, \n",
    "    #           reduce_labels=False,\n",
    "    #       )\n",
    "       \n",
    "    #     avg_test_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "    #     test_mean_iou = metrics[\"mean_iou\"]\n",
    "    #     test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
    "\n",
    "    #      metrics = {\"test_loss\": avg_test_loss, \"test_mean_iou\":test_mean_iou, \"test_mean_accuracy\":test_mean_accuracy}\n",
    "        \n",
    "    #     for k,v in metrics.items():\n",
    "    #         self.log(k,v)\n",
    "        \n",
    "    #     return metrics\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "    \n",
    "    # def test_dataloader(self):\n",
    "    #     return self.test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segformer_finetuner = SegformerFinetuner(\n",
    "    train_dataset.id2label, \n",
    "    train_dataloader=train_dataloader, \n",
    "    val_dataloader=valid_dataloader, \n",
    "    #test_dataloader=test_dataloader, \n",
    "    metrics_interval=10,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    min_delta=0.00, \n",
    "    patience=3, \n",
    "    verbose=False, \n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    max_epochs=500,\n",
    "    val_check_interval=len(train_dataloader),\n",
    ")\n",
    "\n",
    "trainer.fit(segformer_finetuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Fine-tuning을 위한 Trainer 및 TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./your_output_directory\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=feature_extractor,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataloader,\n",
    "    eval_dataset=valid_dataloader,\n",
    ")\n",
    "\n",
    "# Fine-tuning 실행\n",
    "trainer.train()\n",
    "'''\n",
    "\n",
    "class TrainerCustom(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        labels = inputs.get(\"labels\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Fine-tuning을 위한 Trainer 및 TrainingArguments 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./your_output_directory\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = TrainerCustom(\n",
    "    model=feature_extractor,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataloader,\n",
    "    eval_dataset=valid_dataloader,\n",
    ")\n",
    "\n",
    "# Fine-tuning 실행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_IMAGE Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_SH Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_Carbon Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_GT Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_IMAGE Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_SH Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_Carbon Done.\n",
      "C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\label\\SN10_Forest_GT Done.\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import SegformerFeatureExtractor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from dataset import CustomImageDataset\n",
    "\n",
    "local_data_path = 'C:\\Workspace\\Personal\\ccp_data/Training/image/AP10_City_IMAGE'\n",
    "server_data_path = '/mnt/nas27_dataset/Dataset/ccp/Training/image/AP10_City_IMAGE/'\n",
    "home_data_path = 'C:\\Workspace\\ccp\\CarbonCapturePredict-main\\ccp\\Validation\\image\\SN10_Forest_IMAGE'\n",
    "\n",
    "# Fine-tuning에 사용할 데이터셋 클래스 초기화\n",
    "train_dataset = CustomImageDataset(folder_path=home_data_path, transform=None, mode=\"Train\")\n",
    "valid_dataset = CustomImageDataset(folder_path=home_data_path, transform=None, mode=\"Valid\")\n",
    "\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "\n",
    "#for i in range(min(5, len(train_dataset))):\n",
    "    #sample = train_dataset[i]\n",
    "    #print(sample)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basiccuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
